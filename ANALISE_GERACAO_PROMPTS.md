# An√°lise: Gera√ß√£o de ROI Prompts - Compara√ß√£o com Paper Original

## Resumo Executivo

Ap√≥s an√°lise da se√ß√£o 3.1 do paper original (2504.16096v1.pdf), foram identificadas **diferen√ßas significativas** entre o m√©todo descrito no paper e a implementa√ß√£o atual do script `generate_prompts.py`.

---

## üìã O que o Paper Original Descreve (Se√ß√£o 3.1)

### M√©todo de Gera√ß√£o de ROI Prompts:

1. **Gera√ß√£o via ChatGPT**:
   - Os autores usam **ChatGPT** para gerar descri√ß√µes textuais de cada ROI
   - Query enviada ao ChatGPT:
     ```
     "Given the ROI labels for AAL116 atlas, generate a sentence to describe 
     each of them by the given order: Precentral_L, Precentral_R, Frontal_Sup_L ..."
     ```
   - O output s√£o **descri√ß√µes detalhadas** das caracter√≠sticas estruturais e funcionais de cada regi√£o
   - Exemplo mostrado na Fig. 1 do paper:
     - `Precentral_L: The left precentral gyrus, associated with motor control and planning.`
     - `Precentral_R: The right precentral gyrus, involved in executing voluntary motor movements.`
     - `Frontal_Sup_L: The left superior frontal gyrus, plays a role in self-awareness and cognitive control.`

2. **Text Encoder**:
   - Usam **Llama-encoder-1.0B** do LLM2Vec [1]
   - Link: `https://huggingface.co/knowledgator/Llama-encoder-1.0B`
   - O encoder √© **congelado** durante o treinamento

3. **Integra√ß√£o no Modelo**:
   - Os embeddings s√£o projetados para alinhar com a dimens√£o oculta do GNN
   - F√≥rmula: `h^(l)_v = GNN^(l-1)_r(h^(l-1)_v + Enc(p^ROI_v))`
   - O prompt √© **somado** √†s features do n√≥ antes de passar pelo GNN

---

## üîç O que Nossa Implementa√ß√£o Faz

### Script: `generate_prompts.py`

1. **Gera√ß√£o de Prompts**:
   - ‚ùå **N√ÉO usa ChatGPT** para gerar descri√ß√µes
   - ‚úÖ Usa um **template fixo** para todos os ROIs:
     ```python
     prompt = (
         f"The brain region {clean} is associated with functional connectivity "
         f"in autism spectrum disorder."
     )
     ```
   - Exemplo gerado: `"The brain region Precentral L is associated with functional connectivity in autism spectrum disorder."`

2. **Text Encoder**:
   - ‚ùå Usa **SentenceTransformer** com modelo `all-MiniLM-L6-v2`
   - ‚ùå **N√ÉO usa** Llama-encoder-1.0B como especificado no paper

3. **Atlas e ROIs**:
   - ‚úÖ Usa atlas AAL com 116 ROIs (correto)
   - ‚úÖ Carrega labels do nilearn ou lista offline

---

## ‚ö†Ô∏è Diferen√ßas Identificadas

| Aspecto | Paper Original | Nossa Implementa√ß√£o | Status |
|---------|----------------|---------------------|--------|
| **Gera√ß√£o de Texto** | ChatGPT com descri√ß√µes detalhadas | Template fixo gen√©rico | ‚ùå **DIFERENTE** |
| **Text Encoder** | Llama-encoder-1.0B (LLM2Vec) | all-MiniLM-L6-v2 (SentenceTransformer) | ‚ùå **DIFERENTE** |
| **Conte√∫do do Prompt** | Descri√ß√µes estruturais/funcionais espec√≠ficas | Template gen√©rico sobre ASD | ‚ùå **DIFERENTE** |
| **Atlas** | AAL116 (116 ROIs) | AAL116 (116 ROIs) | ‚úÖ **CORRETO** |
| **Congelamento do Encoder** | Sim (congelado) | Sim (n√£o treinado) | ‚úÖ **CORRETO** |

---

## üéØ Impacto das Diferen√ßas

### 1. **Template Fixo vs. Descri√ß√µes do ChatGPT**

**Impacto**: ‚ö†Ô∏è **ALTO**

- O paper usa descri√ß√µes **espec√≠ficas e detalhadas** de cada ROI (ex: "motor control and planning", "self-awareness and cognitive control")
- Nossa implementa√ß√£o usa um template **gen√©rico** que n√£o captura as caracter√≠sticas √∫nicas de cada regi√£o
- Isso pode limitar a capacidade do modelo de distinguir entre diferentes ROIs baseado em conhecimento sem√¢ntico

### 2. **Modelo de Encoder Diferente**

**Impacto**: ‚ö†Ô∏è **M√âDIO**

- `Llama-encoder-1.0B` √© um modelo maior e mais poderoso (1 bilh√£o de par√¢metros)
- `all-MiniLM-L6-v2` √© um modelo menor e mais eficiente (22.7M par√¢metros)
- A qualidade dos embeddings pode ser diferente, mas ambos s√£o modelos de sentence embeddings v√°lidos

### 3. **Falta de Descri√ß√µes Espec√≠ficas**

**Impacto**: ‚ö†Ô∏è **ALTO**

- As descri√ß√µes do ChatGPT fornecem **conhecimento m√©dico espec√≠fico** sobre cada ROI
- O template gen√©rico n√£o aproveita esse conhecimento sem√¢ntico rico
- Isso pode reduzir a capacidade do modelo de incorporar conhecimento externo (um dos objetivos principais do BrainPrompt)

---

## ‚úÖ Recomenda√ß√µes para Alinhamento com o Paper

### Op√ß√£o 1: Implementa√ß√£o Fiel ao Paper (Recomendado)

1. **Gerar descri√ß√µes via ChatGPT/LLM**:
   - Criar um script que gera descri√ß√µes espec√≠ficas para cada ROI usando ChatGPT ou outro LLM
   - Salvar as descri√ß√µes em um arquivo JSON/CSV
   - Exemplo de estrutura:
     ```json
     {
       "Precentral_L": "The left precentral gyrus, associated with motor control and planning.",
       "Precentral_R": "The right precentral gyrus, involved in executing voluntary motor movements.",
       ...
     }
     ```

2. **Usar Llama-encoder-1.0B**:
   - Substituir SentenceTransformer por Llama-encoder-1.0B
   - Instalar: `pip install llm2vec` ou usar diretamente do HuggingFace
   - C√≥digo sugerido:
     ```python
     from llm2vec import LLM2Vec
     model = LLM2Vec.from_pretrained("knowledgator/Llama-encoder-1.0B")
     ```

3. **Atualizar script de gera√ß√£o**:
   - Carregar descri√ß√µes espec√≠ficas de arquivo
   - Usar Llama-encoder-1.0B para codificar
   - Manter o resto da l√≥gica igual

### Op√ß√£o 2: Melhoria Incremental (Pragm√°tica)

1. **Melhorar o template**:
   - Criar templates mais espec√≠ficos baseados em conhecimento m√©dico
   - Exemplo:
     ```python
     ROI_DESCRIPTIONS = {
         "Precentral_L": "motor control and planning",
         "Precentral_R": "executing voluntary motor movements",
         ...
     }
     prompt = f"The brain region {clean} is associated with {ROI_DESCRIPTIONS[label]} and functional connectivity in autism spectrum disorder."
     ```

2. **Manter SentenceTransformer** (mais pr√°tico):
   - `all-MiniLM-L6-v2` √© mais leve e r√°pido
   - Pode ser suficiente se as descri√ß√µes forem melhoradas

### Op√ß√£o 3: H√≠brida (Melhor dos Dois Mundos)

1. **Gerar descri√ß√µes uma vez via ChatGPT/LLM** e salvar
2. **Usar SentenceTransformer** para codificar (mais eficiente)
3. **Atualizar o script** para carregar descri√ß√µes espec√≠ficas

---

## üìù Exemplo de Implementa√ß√£o Sugerida

```python
"""
Gera embeddings textuais (LLM) para as 116 regi√µes do atlas AAL
Alinhado com o paper original BrainPrompt (2504.16096v1)
"""

import os
import torch
import json
from llm2vec import LLM2Vec  # ou usar transformers diretamente

# Descri√ß√µes espec√≠ficas geradas via ChatGPT (uma vez)
ROI_DESCRIPTIONS = {
    "Precentral_L": "The left precentral gyrus, associated with motor control and planning.",
    "Precentral_R": "The right precentral gyrus, involved in executing voluntary motor movements.",
    "Frontal_Sup_L": "The left superior frontal gyrus, plays a role in self-awareness and cognitive control.",
    # ... todas as 116 descri√ß√µes
}

def generate_roi_embeddings(save_dir=None):
    if save_dir is None:
        save_dir = os.path.join(os.path.dirname(__file__), "data")
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, "roi_bert_embeddings.pt")
    
    # Carregar labels AAL
    labels = _aal_labels_offline()  # ou via nilearn
    
    # Construir prompts usando descri√ß√µes espec√≠ficas
    text_prompts = []
    for label in labels:
        if label in ROI_DESCRIPTIONS:
            prompt = ROI_DESCRIPTIONS[label]
        else:
            # Fallback para template gen√©rico
            clean = label.replace("_", " ")
            prompt = f"The brain region {clean} is associated with functional connectivity."
        text_prompts.append(prompt)
    
    # Usar Llama-encoder-1.0B como no paper
    print("Codificando com Llama-encoder-1.0B (LLM2Vec)...")
    model = LLM2Vec.from_pretrained("knowledgator/Llama-encoder-1.0B")
    embeddings = model.encode(text_prompts, convert_to_numpy=True, show_progress_bar=True)
    embeddings = torch.tensor(embeddings, dtype=torch.float32)
    
    torch.save(embeddings, save_path)
    print(f"Salvo em: {save_path}")
    return save_path
```

---

## üî¨ Pr√≥ximos Passos

1. **Decis√£o**: Escolher entre Op√ß√£o 1 (fiel ao paper), Op√ß√£o 2 (pragm√°tica) ou Op√ß√£o 3 (h√≠brida)

2. **Se escolher Op√ß√£o 1 ou 3**:
   - Gerar descri√ß√µes via ChatGPT/LLM para todas as 116 ROIs
   - Salvar em arquivo JSON
   - Atualizar `generate_prompts.py`

3. **Se escolher usar Llama-encoder-1.0B**:
   - Instalar depend√™ncias: `pip install llm2vec` ou usar `transformers`
   - Atualizar c√≥digo de encoding

4. **Testes**:
   - Regenerar embeddings com novo m√©todo
   - Comparar performance com embeddings atuais
   - Verificar se h√° melhoria na capacidade de distinguir ROIs

---

## üìö Refer√™ncias

- Paper: "BrainPrompt: Multi-Level Brain Prompt Enhancement for Neurological Condition Identification" (2504.16096v1)
- Se√ß√£o 3.1: Message-Passing with ROI Prompt Enhancement
- Llama-encoder-1.0B: https://huggingface.co/knowledgator/Llama-encoder-1.0B
- LLM2Vec: https://github.com/McGill-NLP/llm2vec

---

**Data da An√°lise**: 2025-01-17  
**Status**: ‚ö†Ô∏è Implementa√ß√£o atual difere do paper original em aspectos importantes
